{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-dev20191002\n",
      "sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.1\n",
      "numpy 1.17.2\n",
      "pandas 0.25.1\n",
      "sklearn 0.21.3\n",
      "tensorflow 2.0.0-dev20191002\n",
      "tensorflow_core.keras 2.2.4-tf\n",
      "WARNING:tensorflow:From <ipython-input-1-0ef0fca1b7bc>:19: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.experimental.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据类型\n",
    "## 常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[2. 3.]\n",
      " [5. 6.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor([2. 5.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([4. 5. 6.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 常量\n",
    "t = tf.constant([\n",
    "                 [1.,2.,3.],\n",
    "                 [4.,5.,6.]\n",
    "                ])\n",
    "# index\n",
    "print(t)\n",
    "print(t[:,1:])\n",
    "print(t[...,1]) # 取所有第一维中第二维的index为1的值\n",
    "print(t[1,...]) # 取第一维index为1的所有第二维的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[11. 12. 13.]\n",
      " [14. 15. 16.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[14. 32.]\n",
      " [32. 77.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 操作opt\n",
    "print(t+10) # 矩阵中所有的值+10\n",
    "print(tf.square(t))\n",
    "print(t @ tf.transpose(t)) # t与t的转置的矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]]\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# numpy conversion(与numpy之间的互相转换)\n",
    "print(t.numpy()) # tensor转换成numpy\n",
    "print(np.square(t)) # 对转换成numpy的矩阵进行运算\n",
    "np_t = np.array([\n",
    "                 [1.,2.,3.],\n",
    "                 [4.,5.,6.]\n",
    "                ])\n",
    "print(tf.constant(np_t)) # 将numpy转换成tensor对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.718, shape=(), dtype=float32)\n",
      "2.718\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# 0维的就是一个数字，对应于TensorFlow中的Scalars\n",
    "t = tf.constant(2.718)\n",
    "print(t)\n",
    "print(t.numpy())\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'cafe', shape=(), dtype=string)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor([ 99  97 102 101], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# strings\n",
    "t = tf.constant('cafe')\n",
    "print(t)\n",
    "print(tf.strings.length(t))\n",
    "print(tf.strings.length(t,unit=\"UTF8_CHAR\")) # utf8的长度\n",
    "print(tf.strings.unicode_decode(t,'UTF8')) # utf8的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([4 6 2], shape=(3,), dtype=int32)\n",
      "<tf.RaggedTensor [[99, 97, 102, 101], [99, 111, 102, 102, 101, 101], [21654, 21857]]>\n"
     ]
    }
   ],
   "source": [
    "# string array\n",
    "t = tf.constant(['cafe','coffee','咖啡'])\n",
    "print(tf.strings.length(t,unit='UTF8_CHAR')) # 打印出数组中每一个字符串的utf8的长度\n",
    "r = tf.strings.unicode_decode(t,'UTF8')\n",
    "print(r) # RaggedTensor:不规则的tensor，统一维度的数字是不等长的 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RaggedTensor 不规则的Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[11, 12], [21, 22, 23], [], [41]]>\n",
      "tf.Tensor([21 22 23], shape=(3,), dtype=int32)\n",
      "<tf.RaggedTensor [[21, 22, 23]]>\n"
     ]
    }
   ],
   "source": [
    "# ragged tensor\n",
    "r = tf.ragged.constant([\n",
    "    [11,12],\n",
    "    [21,22,23],\n",
    "    [],\n",
    "    [41],\n",
    "])\n",
    "print(r)\n",
    "print(r[1]) # 只取第一行的就是一个一维的tensor\n",
    "print(r[1:2]) # 左闭右开，但是返回的是一个RaggedTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[11, 12], [21, 22, 23], [], [41], [51, 52], [], [71]]>\n"
     ]
    }
   ],
   "source": [
    "# ops on ragged tensor :操作不规则tensor\n",
    "r2 = tf.ragged.constant([[51,52],[],[71]])\n",
    "print(tf.concat([r,r2],axis = 0)) # 在第0维度进行拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[11, 12, 13, 14], [21, 22, 23, 15], [], [41, 41, 42]]>\n"
     ]
    }
   ],
   "source": [
    "# print(tf.concat([r,r2],axis = 1)) # 在第一维进行拼接时 必须保证第0维的行数一致\n",
    "r3 = tf.ragged.constant([[13,14],[15],[],[41,42]])\n",
    "print(tf.concat([r,r3],axis = 1)) # 在第0维一致的情况下是可以进行第一维的拼接的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[11 12  0]\n",
      " [21 22 23]\n",
      " [ 0  0  0]\n",
      " [41  0  0]], shape=(4, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[11 12  1]\n",
      " [21 22 23]\n",
      " [ 1  1  1]\n",
      " [41  1  1]], shape=(4, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(r.to_tensor()) # 将ragged tensor 变成普通的tensor，空位置默认用0补齐\n",
    "print(r.to_tensor(default_value = 1)) # 将空位置用默认值来补齐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Tensor ： 稀疏的Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n",
      "tf.Tensor(\n",
      "[[0. 1. 0. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [0. 0. 0. 3.]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "s = tf.SparseTensor(indices = [[0,1],[1,0],[2,3]], # 有值的位置索引，必须排好序，不然在to_dense会有问题\n",
    "                    values = [1.,2.,3.], # 对应位置的值\n",
    "                    dense_shape = [3,4] # 密集矩阵的shape\n",
    "                   )\n",
    "print(s)\n",
    "print(tf.sparse.to_dense(s)) # 转换成密集矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([2. 4. 6.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n",
      "unsupported operand type(s) for +: 'SparseTensor' and 'int'\n",
      "tf.Tensor(\n",
      "[[ 30.  40.]\n",
      " [ 20.  40.]\n",
      " [210. 240.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# ops on spase tensors\n",
    "s2 = s * 2.0\n",
    "print(s2) # 乘法运算会将对应元素的位置进行乘法运算\n",
    "\n",
    "try:\n",
    "    s3 = s + 1 # spase tensor是不支持加法运算的\n",
    "except TypeError as ex:\n",
    "    print(ex)\n",
    "\n",
    "s4 = tf.constant([[10.,20.],\n",
    "                  [30.,40.],\n",
    "                  [50.,60.],\n",
    "                  [70.,80.]\n",
    "                 ])\n",
    "print(tf.sparse.sparse_dense_matmul(s,s4)) # sparse tensor做矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n",
      "tf.Tensor(\n",
      "[[0. 2. 1. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 3.]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "s_no_order = tf.SparseTensor(indices = [[0,2],[0,1],[2,3]], # 测试如果不排好序\n",
    "                             values = [1.,2.,3.],\n",
    "                            dense_shape = [3,4])\n",
    "print(s_no_order)\n",
    "# print(tf.sparse.to_dense(s_no_order)) # 这种未排序的是不能to_dense的\n",
    "s_order = tf.sparse.reorder(s_no_order) # 调用这个方法排下序列\n",
    "print(tf.sparse.to_dense(s_order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 变量 Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[1., 2., 3.],\n",
      "       [4., 5., 6.]], dtype=float32)>\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor([2. 5.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([4. 5. 6.], shape=(3,), dtype=float32)\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable([[1.,2.,3.],\n",
    "                 [4.,5.,6.]\n",
    "                ])\n",
    "print(v)\n",
    "print(v.value())\n",
    "print(v[:,1])\n",
    "print(v[1,:])\n",
    "print(v.numpy())\n",
    "# 和常量的取值操作完全一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对整个Variable赋值：\n",
      " [[ 64.  84. 192.]\n",
      " [ 14.  16.  18.]]\n",
      "\n",
      "对某个0维度的索引位置赋值：\n",
      " [[ 64.  42. 192.]\n",
      " [ 14.  16.  18.]]\n",
      "\n",
      "对某个维度的一组索引位置赋值：\n",
      " [[ 64.  42. 192.]\n",
      " [  7.   8.   9.]]\n"
     ]
    }
   ],
   "source": [
    "# assign value：对变量重新赋值,只用assign来赋值，不能用=号赋值\n",
    "v.assign(2*v)\n",
    "print(\"对整个Variable赋值：\\n\",v.numpy())\n",
    "v[0,1].assign(42)\n",
    "print(\"\\n对某个0维度的索引位置赋值：\\n\",v.numpy())\n",
    "v[1].assign([7.,8.,9.])\n",
    "print(\"\\n对某个维度的一组索引位置赋值：\\n\",v.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "# 只用assign来赋值，不能用=号赋值\n",
    "try:\n",
    "    v[1] = [4.,8,9,]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
