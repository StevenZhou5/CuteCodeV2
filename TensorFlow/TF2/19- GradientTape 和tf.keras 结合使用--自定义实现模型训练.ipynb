{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.2\n",
      "numpy 1.17.4\n",
      "pandas 0.25.3\n",
      "sklearn 0.22\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "# 在打开网址时出现和ssl证书相关的问题时，需要加上这句话\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# 采用房屋预测模型数据\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all,x_test,y_train_all,y_test = train_test_split(\n",
    "    housing.data,housing.target,random_state = 7)\n",
    "x_train,x_valid,y_train,y_valid = train_test_split(\n",
    "    x_train_all,y_train_all,random_state = 11)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_valid.shape,y_valid.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行数据归一化处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.fit_transform(x_valid)\n",
    "x_test_scaled = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 首先必须了解metric的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# metric的使用\n",
    "metric = keras.metrics.MeanSquaredError() # 均方差\n",
    "print(metric([5.],[2.])) # 接受两个列表参数，求对应的元素差的平方，然后最后在求均值：tf.Tensor(9.0, shape=(), dtype=float32)\n",
    "# metric默认数据会累加\n",
    "print(metric([0.],[1.])) # [(5-2)^2 + (0-1)^2]/2 = 5\n",
    "print(metric.result()) # 这是输出最终的结果\n",
    "\n",
    "# 如果不想metric累加前面的结果需要调用reset_states()\n",
    "metric.reset_states()\n",
    "metric([1.],[3.])\n",
    "print(metric.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29 26 33  2 75 37 95 88 57 73 13 27 17 40  4 10 21 73 45 61 88 18 19  0\n",
      " 80 20 87 56  3 73 98 15]\n"
     ]
    }
   ],
   "source": [
    "test_idx = np.random.randint(0,100,size=32) # 在0-100之间随机取32个数\n",
    "print(test_idx)\n",
    "# print(x_train_scaled[test_idx]) # 会把每个对应索引的1维数据取出来组成一个新的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch: 0 ; Train Mse: 1.4885765 \tValid Mse:1.9255974\n",
      "Epoch: 1 ; Train Mse: 1.6178323  ; Train Mse: 2.3839338 \tValid Mse:1.4302462\n",
      "Epoch: 2 ; Train Mse: 1.2895281 \tValid Mse:1.3988471\n",
      "Epoch: 3 ; Train Mse: 1.2692423 \tValid Mse:1.3938874\n",
      "Epoch: 4 ; Train Mse: 1.2559029 \tValid Mse:1.3932227\n",
      "Epoch: 5 ; Train Mse: 1.2676643 \tValid Mse:1.3906212\n",
      "Epoch: 6 ; Train Mse: 1.2537959 \tValid Mse:1.3915281\n",
      "Epoch: 7 ; Train Mse: 1.2563562 \tValid Mse:1.3900213\n",
      "Epoch: 8 ; Train Mse: 1.242881 \tValid Mse:1.4016278\n",
      "Epoch: 9 ; Train Mse: 1.2635403 \tValid Mse:1.3926986\n",
      "Epoch: 10 ; Train Mse: 1.2719797 \tValid Mse:1.3896056\n",
      "Epoch: 11 ; Train Mse: 1.2459768 \tValid Mse:1.3883191\n",
      "Epoch: 12 ; Train Mse: 1.2481139 \tValid Mse:1.3880839\n",
      "Epoch: 13 ; Train Mse: 1.2713693 \tValid Mse:1.3893563\n",
      "Epoch: 14 ; Train Mse: 1.2621237 \tValid Mse:1.3898783\n",
      "Epoch: 15 ; Train Mse: 1.2350042 \tValid Mse:1.399829\n",
      "Epoch: 16 ; Train Mse: 1.2493849 \tValid Mse:1.3905168\n",
      "Epoch: 17 ; Train Mse: 1.2964941 \tValid Mse:1.3880589\n",
      "Epoch: 18 ; Train Mse: 1.2618 14  \tValid Mse:1.387504\n",
      "Epoch: 19 ; Train Mse: 1.2433009 \tValid Mse:1.3933089\n",
      "Epoch: 20 ; Train Mse: 1.2409811 \tValid Mse:1.3954054\n",
      "Epoch: 21 ; Train Mse: 1.2805332 \tValid Mse:1.3911366\n",
      "Epoch: 22 ; Train Mse: 1.2479137 \tValid Mse:1.3960066\n",
      "Epoch: 23 ; Train Mse: 1.2496396 \tValid Mse:1.3897609\n",
      "Epoch: 24 ; Train Mse: 1.2743082 \tValid Mse:1.3994019\n",
      "Epoch: 25 ; Train Mse: 1.2253711 \tValid Mse:1.3891205\n",
      "Epoch: 26 ; Train Mse: 1.2713128 \tValid Mse:1.3862247\n",
      "Epoch: 27 ; Train Mse: 1.2895076 \tValid Mse:1.3872617\n",
      "Epoch: 28 ; Train Mse: 1.2748246 \tValid Mse:1.3890531\n",
      "Epoch: 29 ; Train Mse: 1.2662927 \tValid Mse:1.3865862\n",
      "Epoch: 30 ; Train Mse: 1.2994355 \tValid Mse:1.390037279 \n",
      "Epoch: 31 ; Train Mse: 1.2215878 \tValid Mse:1.3878374\n",
      "Epoch: 32 ; Train Mse: 1.2387371 \tValid Mse:1.3991399\n",
      "Epoch: 33 ; Train Mse: 1.2276604 \tValid Mse:1.3875234\n",
      "Epoch: 34 ; Train Mse: 1.2428197 \tValid Mse:1.3968031\n",
      "Epoch: 35 ; Train Mse: 1.2661514 \tValid Mse:1.3869957\n",
      "Epoch: 36 ; Train Mse: 1.2505052 \tValid Mse:1.3886558\n",
      "Epoch: 37 ; Train Mse: 1.2475512 \tValid Mse:1.3856641\n",
      "Epoch: 38 ; Train Mse: 1.2762692 \tValid Mse:1.392824\n",
      "Epoch: 39 ; Train Mse: 1.287999 \tValid Mse:1.3856509\n",
      "Epoch: 40 ; Train Mse: 1.2775488 \tValid Mse:1.3864819\n",
      "Epoch: 41 ; Train Mse: 1.2256718 \tValid Mse:1.392517\n",
      "Epoch: 42 ; Train Mse: 1.2435131 \tValid Mse:1.3852848\n",
      "Epoch: 43 ; Train Mse: 1.2542927 \tValid Mse:1.396015\n",
      "Epoch: 44 ; Train Mse: 1.2444355 \tValid Mse:1.3862027\n",
      "Epoch: 45 ; Train Mse: 1.2504264 \tValid Mse:1.3862699\n",
      "Epoch: 46 ; Train Mse: 1.2528661 \tValid Mse:1.3959018\n",
      "Epoch: 47 ; Train Mse: 1.2686098 \tValid Mse:1.3874294\n",
      "Epoch: 48 ; Train Mse: 1.2487411 \tValid Mse:1.3861341\n",
      "Epoch: 49 ; Train Mse: 1.2355913 \tValid Mse:1.3945037\n",
      "Epoch: 50 ; Train Mse: 1.2382627 \tValid Mse:1.3856953\n",
      "Epoch: 51 ; Train Mse: 1.252109 \tValid Mse:1.3858777\n",
      "Epoch: 52 ; Train Mse: 1.2899425 \tValid Mse:1.3930897\n",
      "Epoch: 53 ; Train Mse: 1.2805654 \tValid Mse:1.3850199\n",
      "Epoch: 54 ; Train Mse: 1.2356856 \tValid Mse:1.3910581\n",
      "Epoch: 55 ; Train Mse: 1.2733754 \tValid Mse:1.3901993\n",
      "Epoch: 56 ; Train Mse: 1.2599157 \tValid Mse:1.3892292\n",
      "Epoch: 57 ; Train Mse: 1.2428948 \tValid Mse:1.3902519\n",
      "Epoch: 58 ; Train Mse: 1.2767878 \tValid Mse:1.3870261\n",
      "Epoch: 59 ; Train Mse: 1.2453986 \tValid Mse:1.3875817\n",
      "Epoch: 60 ; Train Mse: 1.2870102 \tValid Mse:1.3847448\n",
      "Epoch: 61 ; Train Mse: 1.2702701 \tValid Mse:1.3844539\n",
      "Epoch: 62 ; Train Mse: 1.2428472 \tValid Mse:1.3860973\n",
      "Epoch: 63 ; Train Mse: 1.2858908 \tValid Mse:1.3878746\n",
      "Epoch: 64 ; Train Mse: 1.2543559 \tValid Mse:1.3852988\n",
      "Epoch: 65 ; Train Mse: 1.299747 \tValid Mse:1.3849845\n",
      "Epoch: 66 ; Train Mse: 1.2349842 \tValid Mse:1.3885732\n",
      "Epoch: 67 ; Train Mse: 1.262417  \tValid Mse:1.3857013\n",
      "Epoch: 68 ; Train Mse: 1.270464 \tValid Mse:1.3848579\n",
      "Epoch: 69 ; Train Mse: 1.2276443  \tValid Mse:1.3910764\n",
      "Epoch: 70 ; Train Mse: 1.2652783 \tValid Mse:1.390602\n",
      "Epoch: 71 ; Train Mse: 1.2271675 \tValid Mse:1.3857379\n",
      "Epoch: 72 ; Train Mse: 1.2488385 \tValid Mse:1.390923\n",
      "Epoch: 73 ; Train Mse: 1.304244 \tValid Mse:1.3873959\n",
      "Epoch: 74 ; Train Mse: 1.2741609 \tValid Mse:1.3857554\n",
      "Epoch: 75 ; Train Mse: 1.2205645 \tValid Mse:1.3895265\n",
      "Epoch: 76 ; Train Mse: 1.2666835 \tValid Mse:1.3862226\n",
      "Epoch: 77 ; Train Mse: 1.2502561 \tValid Mse:1.3847016\n",
      "Epoch: 78 ; Train Mse: 1.2407776 \tValid Mse:1.3864666\n",
      "Epoch: 79 ; Train Mse: 1.2300224  \tValid Mse:1.3867337\n",
      "Epoch: 80 ; Train Mse: 1.2588855 \tValid Mse:1.3878251\n",
      "Epoch: 81 ; Train Mse: 1.2561969 \tValid Mse:1.3848555\n",
      "Epoch: 82 ; Train Mse: 1.2143368 \tValid Mse:1.3954905\n",
      "Epoch: 83 ; Train Mse: 1.2506444 \tValid Mse:1.3846763\n",
      "Epoch: 84 ; Train Mse: 1.260816 \tValid Mse:1.3854707\n",
      "Epoch: 85 ; Train Mse: 1.232981 \tValid Mse:1.3874036\n",
      "Epoch: 86 ; Train Mse: 1.2699474 \tValid Mse:1.3872595\n",
      "Epoch: 87 ; Train Mse: 1.2647334 \tValid Mse:1.3853498\n",
      "Epoch: 88 ; Train Mse: 1.2659646 \tValid Mse:1.3857596\n",
      "Epoch: 89 ; Train Mse: 1.2577583 \tValid Mse:1.3853108\n",
      "Epoch: 90 ; Train Mse: 1.2727168 \tValid Mse:1.3855665\n",
      "Epoch: 91 ; Train Mse: 1.2537935 \tValid Mse:1.3853964\n",
      "Epoch: 92 ; Train Mse: 1.2704617 \tValid Mse:1.39081\n",
      "Epoch: 93 ; Train Mse: 1.2670954 \tValid Mse:1.3874092\n",
      "Epoch: 94 ; Train Mse: 1.2523085 \tValid Mse:1.3866904\n",
      "Epoch: 95 ; Train Mse: 1.2619609 \tValid Mse:1.3867146\n",
      "Epoch: 96 ; Train Mse: 1.2670906 \tValid Mse:1.3843243\n",
      "Epoch: 97 ; Train Mse: 1.2425983 \tValid Mse:1.385305\n",
      "Epoch: 98 ; Train Mse: 1.2275887 \tValid Mse:1.3858565\n",
      "Epoch: 99 ; Train Mse: 1.2445675 \tValid Mse:1.3888923\n"
     ]
    }
   ],
   "source": [
    "# 先定义模型\n",
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(30,activation='relu',input_shape=x_train_scaled.shape[1:]),\n",
    "        keras.layers.Dense(1),\n",
    "    ])\n",
    "\n",
    "# 要实现自定义的模型训练需要做以下几步操作：\n",
    "# 1.按照batch 来去遍历训练集 metric\n",
    "#   1.1 自动求导\n",
    "# 2.epoch结束，验证集 metric\n",
    "\n",
    "epochs = 100 # 需要迭代多少个epochs\n",
    "batch_size = 32 # 每个batch的size\n",
    "steps_per_epoch = len(x_train_scaled) // batch_size # 每迭代一个epoch需要进行多少次梯度下降迭代\n",
    "optimizer = keras.optimizers.SGD() # 用于梯度下降的Optimizer\n",
    "metric = keras.metrics.MeanSquaredError() # 用于计算累计loss的平均值\n",
    "\n",
    "# 定义构建batch的方法\n",
    "def random_batch(x,y,batch_size=32):\n",
    "    idxs = np.random.randint(0,len(x),size=batch_size)\n",
    "    return x[idxs],y[idxs]\n",
    "\n",
    "# 下面我们来实现类似pytorch的自定义实现模型训练\n",
    "for epoch in range(epochs):\n",
    "    metric.reset_states()\n",
    "    for step in range(steps_per_epoch):\n",
    "        # step1: 数据初始化\n",
    "        # 其实这里取batch数据的逻辑时有问题，的因为数据没有去重，且可能不能覆盖到所有数据\n",
    "        x_batch,y_batch = random_batch(x_train_scaled,y_train,batch_size)\n",
    "        \n",
    "        # 计算loss+梯度下降\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch) # 得到预测数据\n",
    "            \n",
    "            # step2：计算loss\n",
    "            loss = tf.reduce_mean(\n",
    "                keras.losses.mean_squared_error(y_batch,y_pred))\n",
    "            metric(y_batch,y_pred) # 累加计算均方差的平均值\n",
    "        # step3：计算梯度\n",
    "        grads = tape.gradient(loss,model.variables)\n",
    "        grads_and_vars = zip(grads,model.variables)\n",
    "        # step4：梯度下降，更新权重\n",
    "        optimizer.apply_gradients(grads_and_vars)\n",
    "        print(\"\\rEpoch:\",epoch,\"; Train Mse:\",metric.result().numpy(),end=\" \")\n",
    "    # 进行验证集的loss计算\n",
    "    y_valid_pred = model(x_valid_scaled)\n",
    "    valid_loss = tf.reduce_mean(keras.losses.mean_squared_error(y_valid,y_valid_pred))\n",
    "    print(\"\\tValid Mse:%s\" % valid_loss.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
