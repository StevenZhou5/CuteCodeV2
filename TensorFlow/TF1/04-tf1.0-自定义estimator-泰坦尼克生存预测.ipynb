{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhenwuzhou/environment/tf1_py3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/zhenwuzhou/environment/tf1_py3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/zhenwuzhou/environment/tf1_py3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/zhenwuzhou/environment/tf1_py3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/zhenwuzhou/environment/tf1_py3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/zhenwuzhou/environment/tf1_py3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "sys.version_info(major=3, minor=7, micro=4, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.2\n",
      "numpy 1.18.1\n",
      "pandas 0.25.3\n",
      "sklearn 0.22.1\n",
      "tensorflow 1.13.1\n",
      "tensorflow._api.v1.keras 2.2.4-tf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl,np,pd,sklearn,tf,keras:\n",
    "    print(module.__name__,module.__version__)\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "================================================================================\n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "# 使用pandas读取csv文件\n",
    "train_file = \"./data/titanic/train.csv\"\n",
    "eval_file = \"./data/titanic/eval.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "print(train_df.head())\n",
    "print(\"=\"*80)\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "================================================================================\n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "================================================================================\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "================================================================================\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_train = train_df.pop(\"survived\")\n",
    "y_eval = eval_df.pop(\"survived\")\n",
    "\n",
    "print(train_df.head())\n",
    "print(\"=\"*80)\n",
    "print(eval_df.head())\n",
    "print(\"=\"*80)\n",
    "print(y_train.head())\n",
    "print(\"=\"*80)\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "# 离散特征:性别，兄弟姐妹和配偶个数，parch父母或孩子是否在船上，'class':仓位上/中/下等仓，\n",
    "# 'deck':货仓还是在夹板上；’embark_town‘:出发的港口，'alone':是否是一个人\n",
    "categorical_columns = ['sex','n_siblings_spouses','parch','class','deck',\n",
    "                       'embark_town','alone']\n",
    "\n",
    "# 连续特征：‘age’，‘fare’:票价\n",
    "numeric_columns = ['age','fare']\n",
    "\n",
    "feature_columns = []\n",
    "# 处理离散特征\n",
    "for categorical_column in categorical_columns:\n",
    "    # 构建词表\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column,vocab) # 打印出对应的离散值词表\n",
    "    # 使用tf.feature_column.categorical_column_with_vocabulary_list构建feature_column\n",
    "    feature_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                        categorical_column,vocab)\n",
    "    # tf.feature_column.indicator_column构建one_hot的feature_column\n",
    "    one_hot_feature_column = tf.feature_column.indicator_column(feature_column)\n",
    "    \n",
    "    # 最后将构建好的feature_column添加到feature_columns列表中\n",
    "    feature_columns.append(one_hot_feature_column)\n",
    "    \n",
    "# 处理连续特征\n",
    "for numeric_column in numeric_columns:\n",
    "    # 构建连续值的feature_column:只需要特征的key值和数据类型\n",
    "    feature_column = tf.feature_column.numeric_column(numeric_column,\n",
    "                                                      dtype=tf.float32)\n",
    "    feature_columns.append(feature_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义构建dataset的方法\n",
    "def make_dataset(data_df, label_df, epochs = 10,shuffle = True,batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(data_df),label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'customized_estimator', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x156de5390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into customized_estimator/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.3825464, step = 1\n",
      "INFO:tensorflow:global_step/sec: 545.688\n",
      "INFO:tensorflow:loss = 0.6506024, step = 101 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 1181.75\n",
      "INFO:tensorflow:loss = 0.42021447, step = 201 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1221.34\n",
      "INFO:tensorflow:loss = 0.58546126, step = 301 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1209.18\n",
      "INFO:tensorflow:loss = 0.28174186, step = 401 (0.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 1173.83\n",
      "INFO:tensorflow:loss = 0.4774403, step = 501 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1186.94\n",
      "INFO:tensorflow:loss = 0.3774882, step = 601 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1188.64\n",
      "INFO:tensorflow:loss = 0.45326355, step = 701 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1168.51\n",
      "INFO:tensorflow:loss = 0.30793488, step = 801 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1153\n",
      "INFO:tensorflow:loss = 0.24636355, step = 901 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1150.74\n",
      "INFO:tensorflow:loss = 0.2897247, step = 1001 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1182.47\n",
      "INFO:tensorflow:loss = 0.22673325, step = 1101 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1109.61\n",
      "INFO:tensorflow:loss = 0.61223197, step = 1201 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1153.22\n",
      "INFO:tensorflow:loss = 0.3732309, step = 1301 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1117.25\n",
      "INFO:tensorflow:loss = 0.29649144, step = 1401 (0.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 1160.46\n",
      "INFO:tensorflow:loss = 0.27189195, step = 1501 (0.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 1147.25\n",
      "INFO:tensorflow:loss = 0.3346352, step = 1601 (0.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 1219.6\n",
      "INFO:tensorflow:loss = 0.29945487, step = 1701 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 1245.95\n",
      "INFO:tensorflow:loss = 0.3668416, step = 1801 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1243.36\n",
      "INFO:tensorflow:loss = 0.27069253, step = 1901 (0.080 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1960 into customized_estimator/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.44028917.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x156ddb650>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"customized_estimator\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "#自定义mode_fn\n",
    "def model_fn(features,labels,mode,params):\n",
    "    # model 指的就是模型的运行时状态: Train,Eval,Predict\n",
    "    input_for_next_layer = tf.feature_column.input_layer(\n",
    "        features,params[\"feature_columns\"]) # 输入层\n",
    "    for n_unit in params[\"hidden_units\"]: # 隐藏层\n",
    "        input_for_next_layer = tf.layers.dense(input_for_next_layer,\n",
    "                                               units=n_unit,\n",
    "                                               activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(input_for_next_layer,\n",
    "                             units=params[\"n_classes\"],\n",
    "                             activation=None)\n",
    "    predicted_classes = tf.argmax(logits,1)\n",
    "    \n",
    "    # model_fn方法必须返回一个tf.estimator.EstimatorSpec()对象\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # 在预测模式下，不需要计算loss和准确率，只需要计算预测值\n",
    "        predictions = {\n",
    "            \"class_ids\": predicted_classes[:,tf.newaxis],\n",
    "            \"probabilities\": tf.nn.softmax(logits),\n",
    "            \"logits\":logits\n",
    "        } \n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode,predictions = predictions)\n",
    "    # loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels,\n",
    "                                                  logits = logits)\n",
    "    # tf.metrics.accuracy可以累积求平均计算准确率\n",
    "    accuracy = tf.metrics.accuracy(labels = labels,\n",
    "                                   predictions = predicted_classes,\n",
    "                                   name = \"acc_op\")\n",
    "    metrics = {\n",
    "        \"accuracy\":accuracy\n",
    "    }\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode,loss = loss,\n",
    "                                          eval_metric_ops = metrics)\n",
    "    # 在训练的时候才需要的train_op\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = optimizer.minimize(\n",
    "        loss, global_step = tf.train.get_global_step())\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode,loss = loss,\n",
    "                                          train_op = train_op)\n",
    "    \n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn = model_fn,\n",
    "    model_dir = output_dir,\n",
    "    params = {\n",
    "        \"feature_columns\":feature_columns,\n",
    "        \"hidden_units\":[100,100],\n",
    "        \"n_classes\":2\n",
    "    })\n",
    "estimator.train(input_fn = lambda : make_dataset(train_df,y_train,epochs = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-09T09:10:39Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /Users/zhenwuzhou/environment/tf1_py3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from customized_estimator/model.ckpt-1960\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-09-09:10:40\n",
      "INFO:tensorflow:Saving dict for global step 1960: accuracy = 0.7878788, global_step = 1960, loss = 0.5543977\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1960: customized_estimator/model.ckpt-1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7878788, 'loss': 0.5543977, 'global_step': 1960}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(lambda:make_dataset(eval_df,y_eval,epochs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
